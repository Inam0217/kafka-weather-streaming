# ğŸŒ¦ï¸ Kafka Weather Streaming ETL

A real-time streaming data pipeline using **Apache Kafka**, **Python**, and **MySQL** to ingest, process, and store live weather data.

---

## ğŸ“Œ Project Overview
This project demonstrates:
- Producing weather data events with a Kafka **Producer**.
- Consuming events in real-time with a Kafka **Consumer**.
- Storing processed records in **MySQL**.
- A simple, production-style streaming ETL pipeline.

---

## âš™ï¸ Tech Stack
- **Apache Kafka** (Dockerized)
- **Python** (Producer & Consumer)
- **MySQL** (Database)
- **Docker Compose**
- **OpenWeather API** (Data source)

---

## ğŸ› ï¸ Project Structure
```
kafka-weather-streaming/
â”‚â”€â”€ docker-compose.yml        # Kafka & MySQL services
â”‚â”€â”€ requirements.txt          # Python dependencies
â”‚â”€â”€ producer_mock.py          # Test producer with mock data
â”‚â”€â”€ producer_openweather.py   # Producer using OpenWeather API
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ consumer_mysql.py     # Consumer saving data into MySQL
â”‚   â”œâ”€â”€ consumer_print.py     # Consumer printing data to console
â”‚   â”œâ”€â”€ producer_openweather_fast.py   # Fast producer variant
â”‚   â””â”€â”€ producer_openweather_loop.py   # Loop-based producer
â”‚â”€â”€ .env.example              # Safe template for environment variables
â”‚â”€â”€ README.md                 # Documentation
```

---

## ğŸš€ How It Works
```mermaid
graph TD
    A[Weather Producer] -->|JSON Messages| B[Kafka Topic]
    B --> C[Consumer]
    C --> D[MySQL Database]
```

---

## â–¶ï¸ Getting Started
1. Clone the repository:
   ```bash
   git clone https://github.com/Inam0217/kafka-weather-streaming.git
   cd kafka-weather-streaming
   ```

2. Create `.env` (based on `.env.example`) with your DB & API settings.

3. Start Kafka + MySQL:
   ```bash
   docker-compose up -d
   ```

4. Run a producer:
   ```bash
   python producer_openweather.py
   ```

5. Run a consumer:
   ```bash
   python src/consumer_mysql.py
   ```

---

## ğŸ“‚ Assets

### ETL Pipeline
![ETL Pipeline](assets/etl_flow.png)

### Kafka Producer & Consumer Logs
![Producer Consumer Logs](assets/consumer_producer_output.png)

### MySQL Table Output
![MySQL Table](assets/mysql_table_output.png)

---

## ğŸ”® Future Work
- Add **Spark Structured Streaming** for transformations.
- Deploy to **Confluent Cloud / AWS MSK**.
- Build a **Grafana Dashboard** for live monitoring.

---

ğŸ‘¨â€ğŸ’» Built with â¤ï¸ by **Inam Ul Hassan**
